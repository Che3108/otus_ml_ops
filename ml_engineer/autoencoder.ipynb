{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "265979fa-d42b-43fe-91f1-79bfe3ecc22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-23 02:48:51.086390: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-23 02:48:51.088549: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-23 02:48:51.118969: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-23 02:48:51.685718: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# библиотеки\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.layers import UpSampling2D, Reshape, Flatten, Conv2DTranspose\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a97335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузка датасета\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d59c7cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_conv.shape = (60000, 28, 28, 1)\n",
      "x_test_conv.shape  = (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# предподготовка данных\n",
    "# нормируем и приведем к требуемому формату данные\n",
    "x_train_conv = x_train.astype('float32') / 255.\n",
    "x_test_conv  = x_test.astype('float32') / 255.\n",
    "x_train_conv = np.expand_dims(x_train_conv, -1)\n",
    "x_test_conv  = np.expand_dims(x_test_conv, -1)\n",
    "print('x_train_conv.shape =', x_train_conv.shape)\n",
    "print('x_test_conv.shape  =', x_test_conv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e60e40d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# нейронная сеть\n",
    "img_input = Input((28,28,1))\n",
    "\n",
    "x = Conv2D(32, (3, 3), padding='same', activation='relu')(img_input)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(32, (3, 3), padding='same', activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D()(x)\n",
    "\n",
    "x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "z = MaxPooling2D()(x)\n",
    "\n",
    "x = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same', activation='relu')(z)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same', activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(32, (3, 3), padding='same', activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(32, (3, 3), padding='same', activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "model = Model(img_input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c40bb064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# компиляция\n",
    "model.compile(\n",
    "    loss='mse',\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb856dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "es = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
    "mch = ModelCheckpoint(\n",
    "    \"autoencoder.keras\",\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='min',\n",
    "    save_freq='epoch'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "230282de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314ms/step - accuracy: 0.7317 - loss: 0.0944\n",
      "Epoch 1: val_loss improved from inf to 0.01413, saving model to autoencoder.keras\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 322ms/step - accuracy: 0.7318 - loss: 0.0943 - val_accuracy: 0.8132 - val_loss: 0.0141\n",
      "Epoch 2/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.8149 - loss: 0.0097\n",
      "Epoch 2: val_loss improved from 0.01413 to 0.00588, saving model to autoencoder.keras\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 309ms/step - accuracy: 0.8149 - loss: 0.0097 - val_accuracy: 0.8143 - val_loss: 0.0059\n",
      "Epoch 3/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.8155 - loss: 0.0056\n",
      "Epoch 3: val_loss improved from 0.00588 to 0.00429, saving model to autoencoder.keras\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 314ms/step - accuracy: 0.8155 - loss: 0.0056 - val_accuracy: 0.8144 - val_loss: 0.0043\n",
      "Epoch 4/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.8151 - loss: 0.0039\n",
      "Epoch 4: val_loss improved from 0.00429 to 0.00321, saving model to autoencoder.keras\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 309ms/step - accuracy: 0.8151 - loss: 0.0039 - val_accuracy: 0.8144 - val_loss: 0.0032\n",
      "Epoch 5/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - accuracy: 0.8159 - loss: 0.0030\n",
      "Epoch 5: val_loss improved from 0.00321 to 0.00253, saving model to autoencoder.keras\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 308ms/step - accuracy: 0.8159 - loss: 0.0030 - val_accuracy: 0.8145 - val_loss: 0.0025\n",
      "Epoch 6/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - accuracy: 0.8155 - loss: 0.0025\n",
      "Epoch 6: val_loss improved from 0.00253 to 0.00220, saving model to autoencoder.keras\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 304ms/step - accuracy: 0.8155 - loss: 0.0025 - val_accuracy: 0.8145 - val_loss: 0.0022\n",
      "Epoch 7/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.8157 - loss: 0.0021\n",
      "Epoch 7: val_loss improved from 0.00220 to 0.00194, saving model to autoencoder.keras\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 312ms/step - accuracy: 0.8157 - loss: 0.0021 - val_accuracy: 0.8145 - val_loss: 0.0019\n",
      "Epoch 8/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - accuracy: 0.8154 - loss: 0.0018\n",
      "Epoch 8: val_loss did not improve from 0.00194\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 310ms/step - accuracy: 0.8154 - loss: 0.0018 - val_accuracy: 0.8145 - val_loss: 0.0020\n",
      "Epoch 9/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - accuracy: 0.8152 - loss: 0.0016\n",
      "Epoch 9: val_loss improved from 0.00194 to 0.00141, saving model to autoencoder.keras\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 308ms/step - accuracy: 0.8153 - loss: 0.0016 - val_accuracy: 0.8145 - val_loss: 0.0014\n",
      "Epoch 10/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.8154 - loss: 0.0014\n",
      "Epoch 10: val_loss did not improve from 0.00141\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 311ms/step - accuracy: 0.8154 - loss: 0.0014 - val_accuracy: 0.8145 - val_loss: 0.0016\n",
      "Epoch 11/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.8156 - loss: 0.0013\n",
      "Epoch 11: val_loss improved from 0.00141 to 0.00120, saving model to autoencoder.keras\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 311ms/step - accuracy: 0.8156 - loss: 0.0013 - val_accuracy: 0.8145 - val_loss: 0.0012\n",
      "Epoch 12/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.8151 - loss: 0.0012\n",
      "Epoch 12: val_loss did not improve from 0.00120\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 312ms/step - accuracy: 0.8151 - loss: 0.0012 - val_accuracy: 0.8145 - val_loss: 0.0014\n",
      "Epoch 13/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - accuracy: 0.8155 - loss: 0.0011\n",
      "Epoch 13: val_loss improved from 0.00120 to 0.00109, saving model to autoencoder.keras\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 310ms/step - accuracy: 0.8155 - loss: 0.0011 - val_accuracy: 0.8145 - val_loss: 0.0011\n",
      "Epoch 14/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.8154 - loss: 0.0011\n",
      "Epoch 14: val_loss improved from 0.00109 to 0.00094, saving model to autoencoder.keras\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 310ms/step - accuracy: 0.8154 - loss: 0.0011 - val_accuracy: 0.8145 - val_loss: 9.4484e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.8156 - loss: 9.8030e-04\n",
      "Epoch 15: val_loss improved from 0.00094 to 0.00093, saving model to autoencoder.keras\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 309ms/step - accuracy: 0.8156 - loss: 9.8028e-04 - val_accuracy: 0.8145 - val_loss: 9.2735e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - accuracy: 0.8154 - loss: 9.2963e-04\n",
      "Epoch 16: val_loss improved from 0.00093 to 0.00086, saving model to autoencoder.keras\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 309ms/step - accuracy: 0.8154 - loss: 9.2960e-04 - val_accuracy: 0.8145 - val_loss: 8.5508e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.8156 - loss: 8.6871e-04\n",
      "Epoch 17: val_loss improved from 0.00086 to 0.00085, saving model to autoencoder.keras\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 308ms/step - accuracy: 0.8156 - loss: 8.6871e-04 - val_accuracy: 0.8145 - val_loss: 8.4524e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.8151 - loss: 8.4415e-04\n",
      "Epoch 18: val_loss improved from 0.00085 to 0.00077, saving model to autoencoder.keras\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 309ms/step - accuracy: 0.8151 - loss: 8.4413e-04 - val_accuracy: 0.8145 - val_loss: 7.6929e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - accuracy: 0.8160 - loss: 7.9605e-04\n",
      "Epoch 19: val_loss did not improve from 0.00077\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 309ms/step - accuracy: 0.8160 - loss: 7.9602e-04 - val_accuracy: 0.8145 - val_loss: 7.9519e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.8156 - loss: 7.5978e-04\n",
      "Epoch 20: val_loss improved from 0.00077 to 0.00073, saving model to autoencoder.keras\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 309ms/step - accuracy: 0.8156 - loss: 7.5977e-04 - val_accuracy: 0.8145 - val_loss: 7.3402e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - accuracy: 0.8155 - loss: 7.2531e-04\n",
      "Epoch 21: val_loss improved from 0.00073 to 0.00068, saving model to autoencoder.keras\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 310ms/step - accuracy: 0.8155 - loss: 7.2531e-04 - val_accuracy: 0.8145 - val_loss: 6.7549e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.8153 - loss: 7.1802e-04\n",
      "Epoch 22: val_loss did not improve from 0.00068\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 309ms/step - accuracy: 0.8153 - loss: 7.1801e-04 - val_accuracy: 0.8145 - val_loss: 7.5952e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - accuracy: 0.8156 - loss: 6.7643e-04\n",
      "Epoch 23: val_loss improved from 0.00068 to 0.00063, saving model to autoencoder.keras\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 308ms/step - accuracy: 0.8156 - loss: 6.7643e-04 - val_accuracy: 0.8145 - val_loss: 6.3016e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - accuracy: 0.8155 - loss: 6.5554e-04\n",
      "Epoch 24: val_loss improved from 0.00063 to 0.00062, saving model to autoencoder.keras\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 310ms/step - accuracy: 0.8155 - loss: 6.5554e-04 - val_accuracy: 0.8145 - val_loss: 6.1551e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.8153 - loss: 6.4099e-04\n",
      "Epoch 25: val_loss improved from 0.00062 to 0.00060, saving model to autoencoder.keras\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 311ms/step - accuracy: 0.8153 - loss: 6.4098e-04 - val_accuracy: 0.8145 - val_loss: 5.9950e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.8153 - loss: 6.1659e-04\n",
      "Epoch 26: val_loss did not improve from 0.00060\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 309ms/step - accuracy: 0.8153 - loss: 6.1658e-04 - val_accuracy: 0.8145 - val_loss: 6.0389e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.8153 - loss: 6.1068e-04\n",
      "Epoch 27: val_loss improved from 0.00060 to 0.00058, saving model to autoencoder.keras\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 309ms/step - accuracy: 0.8153 - loss: 6.1065e-04 - val_accuracy: 0.8145 - val_loss: 5.8412e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - accuracy: 0.8157 - loss: 5.8417e-04\n",
      "Epoch 28: val_loss did not improve from 0.00058\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 308ms/step - accuracy: 0.8157 - loss: 5.8417e-04 - val_accuracy: 0.8145 - val_loss: 9.7214e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - accuracy: 0.8156 - loss: 6.0949e-04\n",
      "Epoch 29: val_loss improved from 0.00058 to 0.00054, saving model to autoencoder.keras\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 308ms/step - accuracy: 0.8156 - loss: 6.0942e-04 - val_accuracy: 0.8145 - val_loss: 5.3784e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - accuracy: 0.8157 - loss: 5.5401e-04\n",
      "Epoch 30: val_loss did not improve from 0.00054\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 307ms/step - accuracy: 0.8157 - loss: 5.5401e-04 - val_accuracy: 0.8145 - val_loss: 5.5303e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.8156 - loss: 5.3441e-04\n",
      "Epoch 31: val_loss improved from 0.00054 to 0.00053, saving model to autoencoder.keras\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 309ms/step - accuracy: 0.8156 - loss: 5.3440e-04 - val_accuracy: 0.8145 - val_loss: 5.2613e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - accuracy: 0.8149 - loss: 5.2634e-04\n",
      "Epoch 32: val_loss improved from 0.00053 to 0.00052, saving model to autoencoder.keras\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 307ms/step - accuracy: 0.8149 - loss: 5.2633e-04 - val_accuracy: 0.8145 - val_loss: 5.1893e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - accuracy: 0.8155 - loss: 5.1163e-04\n",
      "Epoch 33: val_loss improved from 0.00052 to 0.00049, saving model to autoencoder.keras\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 307ms/step - accuracy: 0.8155 - loss: 5.1162e-04 - val_accuracy: 0.8145 - val_loss: 4.9275e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - accuracy: 0.8152 - loss: 5.0106e-04\n",
      "Epoch 34: val_loss improved from 0.00049 to 0.00048, saving model to autoencoder.keras\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 307ms/step - accuracy: 0.8152 - loss: 5.0106e-04 - val_accuracy: 0.8145 - val_loss: 4.8442e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.8151 - loss: 4.9077e-04\n",
      "Epoch 35: val_loss improved from 0.00048 to 0.00047, saving model to autoencoder.keras\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 309ms/step - accuracy: 0.8151 - loss: 4.9077e-04 - val_accuracy: 0.8145 - val_loss: 4.7416e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - accuracy: 0.8159 - loss: 4.7028e-04\n",
      "Epoch 36: val_loss improved from 0.00047 to 0.00047, saving model to autoencoder.keras\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 310ms/step - accuracy: 0.8159 - loss: 4.7028e-04 - val_accuracy: 0.8145 - val_loss: 4.6909e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - accuracy: 0.8152 - loss: 4.6756e-04\n",
      "Epoch 37: val_loss did not improve from 0.00047\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 310ms/step - accuracy: 0.8152 - loss: 4.6756e-04 - val_accuracy: 0.8145 - val_loss: 4.9287e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - accuracy: 0.8155 - loss: 4.5969e-04\n",
      "Epoch 38: val_loss improved from 0.00047 to 0.00044, saving model to autoencoder.keras\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 305ms/step - accuracy: 0.8155 - loss: 4.5968e-04 - val_accuracy: 0.8145 - val_loss: 4.4407e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - accuracy: 0.8159 - loss: 4.4926e-04\n",
      "Epoch 39: val_loss improved from 0.00044 to 0.00044, saving model to autoencoder.keras\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 307ms/step - accuracy: 0.8159 - loss: 4.4925e-04 - val_accuracy: 0.8145 - val_loss: 4.3519e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - accuracy: 0.8150 - loss: 4.3947e-04\n",
      "Epoch 40: val_loss did not improve from 0.00044\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 307ms/step - accuracy: 0.8150 - loss: 4.3947e-04 - val_accuracy: 0.8145 - val_loss: 4.5008e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - accuracy: 0.8156 - loss: 4.2901e-04\n",
      "Epoch 41: val_loss improved from 0.00044 to 0.00043, saving model to autoencoder.keras\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 306ms/step - accuracy: 0.8156 - loss: 4.2900e-04 - val_accuracy: 0.8145 - val_loss: 4.2509e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - accuracy: 0.8152 - loss: 4.2223e-04\n",
      "Epoch 42: val_loss did not improve from 0.00043\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 307ms/step - accuracy: 0.8152 - loss: 4.2222e-04 - val_accuracy: 0.8145 - val_loss: 4.2822e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - accuracy: 0.8157 - loss: 4.1407e-04\n",
      "Epoch 43: val_loss improved from 0.00043 to 0.00042, saving model to autoencoder.keras\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 308ms/step - accuracy: 0.8157 - loss: 4.1406e-04 - val_accuracy: 0.8145 - val_loss: 4.1632e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - accuracy: 0.8154 - loss: 4.0256e-04\n",
      "Epoch 44: val_loss improved from 0.00042 to 0.00040, saving model to autoencoder.keras\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 306ms/step - accuracy: 0.8154 - loss: 4.0256e-04 - val_accuracy: 0.8145 - val_loss: 3.9992e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - accuracy: 0.8156 - loss: 3.9809e-04\n",
      "Epoch 45: val_loss improved from 0.00040 to 0.00040, saving model to autoencoder.keras\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 305ms/step - accuracy: 0.8156 - loss: 3.9810e-04 - val_accuracy: 0.8145 - val_loss: 3.9595e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - accuracy: 0.8155 - loss: 3.9272e-04\n",
      "Epoch 46: val_loss improved from 0.00040 to 0.00038, saving model to autoencoder.keras\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 305ms/step - accuracy: 0.8155 - loss: 3.9273e-04 - val_accuracy: 0.8145 - val_loss: 3.8266e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - accuracy: 0.8155 - loss: 3.8560e-04\n",
      "Epoch 47: val_loss did not improve from 0.00038\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 306ms/step - accuracy: 0.8155 - loss: 3.8560e-04 - val_accuracy: 0.8145 - val_loss: 3.8722e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - accuracy: 0.8154 - loss: 3.7962e-04\n",
      "Epoch 48: val_loss improved from 0.00038 to 0.00037, saving model to autoencoder.keras\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 305ms/step - accuracy: 0.8154 - loss: 3.7961e-04 - val_accuracy: 0.8145 - val_loss: 3.7371e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - accuracy: 0.8158 - loss: 3.7484e-04\n",
      "Epoch 49: val_loss did not improve from 0.00037\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 305ms/step - accuracy: 0.8158 - loss: 3.7484e-04 - val_accuracy: 0.8145 - val_loss: 3.8614e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - accuracy: 0.8156 - loss: 3.7005e-04\n",
      "Epoch 50: val_loss improved from 0.00037 to 0.00037, saving model to autoencoder.keras\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 302ms/step - accuracy: 0.8156 - loss: 3.7004e-04 - val_accuracy: 0.8145 - val_loss: 3.7123e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - accuracy: 0.8157 - loss: 3.6273e-04\n",
      "Epoch 51: val_loss did not improve from 0.00037\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 302ms/step - accuracy: 0.8157 - loss: 3.6273e-04 - val_accuracy: 0.8145 - val_loss: 3.9832e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - accuracy: 0.8156 - loss: 3.5835e-04\n",
      "Epoch 52: val_loss improved from 0.00037 to 0.00035, saving model to autoencoder.keras\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 308ms/step - accuracy: 0.8156 - loss: 3.5835e-04 - val_accuracy: 0.8145 - val_loss: 3.5420e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - accuracy: 0.8155 - loss: 3.5137e-04\n",
      "Epoch 53: val_loss did not improve from 0.00035\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 306ms/step - accuracy: 0.8155 - loss: 3.5137e-04 - val_accuracy: 0.8145 - val_loss: 3.5546e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - accuracy: 0.8154 - loss: 3.4939e-04\n",
      "Epoch 54: val_loss improved from 0.00035 to 0.00035, saving model to autoencoder.keras\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 307ms/step - accuracy: 0.8154 - loss: 3.4939e-04 - val_accuracy: 0.8145 - val_loss: 3.4659e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - accuracy: 0.8156 - loss: 3.4687e-04\n",
      "Epoch 55: val_loss did not improve from 0.00035\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 306ms/step - accuracy: 0.8156 - loss: 3.4687e-04 - val_accuracy: 0.8145 - val_loss: 3.6221e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - accuracy: 0.8155 - loss: 3.3927e-04\n",
      "Epoch 56: val_loss did not improve from 0.00035\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 304ms/step - accuracy: 0.8155 - loss: 3.3927e-04 - val_accuracy: 0.8145 - val_loss: 3.4870e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - accuracy: 0.8155 - loss: 3.3752e-04\n",
      "Epoch 57: val_loss did not improve from 0.00035\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 299ms/step - accuracy: 0.8155 - loss: 3.3752e-04 - val_accuracy: 0.8145 - val_loss: 3.7952e-04\n",
      "Epoch 57: early stopping\n"
     ]
    }
   ],
   "source": [
    "# обучение\n",
    "history = model.fit(\n",
    "    x = x_train_conv,\n",
    "    y = x_train_conv,\n",
    "    batch_size = 128,\n",
    "    epochs = 100,\n",
    "    validation_data = (x_test_conv, x_test_conv),\n",
    "    verbose = 1,\n",
    "    callbacks = [mch, es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4757ab3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./autoencoder.keras to s3://cherepanov-bucket/autoencoder.keras\n"
     ]
    }
   ],
   "source": [
    "# копируем полученную модель на s3-хранилище\n",
    "!aws --endpoint-url=https://storage.yandexcloud.net/ s3 cp autoencoder.keras s3://cherepanov-bucket/autoencoder.keras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
